{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ee6521e-c28b-40d4-97b5-b57a1498f141",
   "metadata": {},
   "source": [
    "# Fraud Detection - Multiclass Classification\n",
    "## Machine Learning I - Group Project\n",
    "\n",
    "**Objective:** E-commerce fraud detection using multiclass classification (Legitimate, Suspicious, Fraudulent)\n",
    "\n",
    "**Authors:** [Your Names]  \n",
    "**Date:** December 2024\n",
    "\n",
    "---\n",
    "\n",
    "### Methodology:\n",
    "- **4 ML Algorithms:** ANNs (8 topologies), SVMs (10 configs), Decision Trees (7 depths), kNN (6 k values)\n",
    "- **Ensemble Methods:** Majority Voting + Weighted Voting\n",
    "- **Dataset:** 1.5M e-commerce transactions â†’ 3-class risk assessment\n",
    "- **Cross-Validation:** 3-fold stratified on training set\n",
    "- **Evaluation:** Hold-out test set (20%)\n",
    "\n",
    "### Code Organization:\n",
    "```\n",
    "/project/\n",
    "â”œâ”€â”€ main.jl                    â† This file (executable from top to bottom)\n",
    "â”œâ”€â”€ /utils/\n",
    "â”‚   â”œâ”€â”€ utils.jl              â† Course utilities (includes modelCrossValidation)\n",
    "â”‚   â””â”€â”€ preprocessing.jl      â† Custom preprocessing functions\n",
    "â””â”€â”€ /datasets/\n",
    "    â””â”€â”€ Fraudulent_E-Commerce_Transaction_Data_merge.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be78a1c4-2880-4800-923c-b09809f18793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "#                    SETUP & IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "using Random\n",
    "Random.seed!(42)\n",
    "\n",
    "# Load packages\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Statistics\n",
    "using Dates\n",
    "using StatsBase\n",
    "using Plots\n",
    "using StatsPlots     \n",
    "using HypothesisTests\n",
    "using Pkg\n",
    "\n",
    "println(\"âœ… Packages loaded!\")\n",
    "\n",
    "# Load course utilities\n",
    "include(\"utils/utils.jl\")\n",
    "println(\"âœ… Course utilities loaded (includes modelCrossValidation, confusionMatrix, etc.)\")\n",
    "\n",
    "include(\"utils/visualization.jl\")\n",
    "\n",
    "# Load custom preprocessing\n",
    "include(\"utils/preprocessing.jl\")\n",
    "using .PreprocessingUtils\n",
    "println(\"âœ… Custom preprocessing utilities loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d17870d-b83f-4322-ae10-f019621c1a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "#  HELPER FUNCTIONS: ENSEMBLE VOTING\n",
    "# ============================================================================\n",
    "\n",
    "function majorityVoting(predictions::Vector{Vector{String}})\n",
    "    n_samples = length(predictions[1])\n",
    "    ensemble_predictions = Vector{String}(undef, n_samples)\n",
    "    for i in 1:n_samples\n",
    "        votes = [pred[i] for pred in predictions]\n",
    "        ensemble_predictions[i] = mode(votes)\n",
    "    end\n",
    "    return ensemble_predictions\n",
    "end\n",
    "\n",
    "function weightedVoting(predictions::Vector{Vector{String}}, weights::Vector{Float64})\n",
    "    n_samples = length(predictions[1])\n",
    "    n_models = length(predictions)\n",
    "    # Raccogli tutte le classi uniche\n",
    "    classes_unique = sort(unique(vcat(predictions...)))\n",
    "    \n",
    "    ensemble_predictions = Vector{String}(undef, n_samples)\n",
    "    for i in 1:n_samples\n",
    "        class_scores = Dict(c => 0.0 for c in classes_unique)\n",
    "        for j in 1:n_models\n",
    "            class_pred = predictions[j][i]\n",
    "            if haskey(class_scores, class_pred)\n",
    "                class_scores[class_pred] += weights[j]\n",
    "            end\n",
    "        end\n",
    "        ensemble_predictions[i] = argmax(class_scores)\n",
    "    end\n",
    "    return ensemble_predictions\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb47e1f2-2b47-442c-8c91-0bc5ab2dc530",
   "metadata": {},
   "outputs": [],
   "source": [
    "function evaluate_approach(approach_name, train_inputs, train_targets, test_inputs, test_targets; cv_folds=3)\n",
    "    println(\"\\n\" * \"=\"^80)\n",
    "    println(\"ðŸš€ EVALUATING APPROACH: $approach_name\")\n",
    "    println(\"=\"^80)\n",
    "    \n",
    "    cv_indices = crossvalidation(train_targets, cv_folds)\n",
    "    final_results = Dict{String, Dict{String, Float64}}()\n",
    "    \n",
    "    # --- PREPARAZIONE DATI ---\n",
    "    train_targets_str = string.(train_targets)\n",
    "    test_targets_str = string.(test_targets)\n",
    "    classes_str = sort(unique(train_targets_str))\n",
    "    classes_int = sort(unique(train_targets))\n",
    "    \n",
    "    # One-Hot Encoding per ANN\n",
    "    if length(classes_int) == 2\n",
    "        train_targets_onehot = reshape(train_targets .== classes_int[2], :, 1)\n",
    "        test_targets_onehot  = reshape(test_targets  .== classes_int[2], :, 1)\n",
    "    else\n",
    "        train_targets_onehot = oneHotEncoding(train_targets, classes_int)\n",
    "        test_targets_onehot = oneHotEncoding(test_targets, classes_int)\n",
    "    end\n",
    "    \n",
    "    # --- FIX PUNTO 2: Normalizzazione Condizionale ---\n",
    "    # Se do_normalize Ã¨ true (default), normalizziamo qui per il training finale\n",
    "    # e passiamo normalize=true al CV. Se Ã¨ false (es. PCA), usiamo i dati cosÃ¬ come sono.\n",
    "    local train_inputs_ready, test_inputs_ready\n",
    "    \n",
    "    if do_normalize\n",
    "        normParams = calculateMinMaxNormalizationParameters(train_inputs)\n",
    "        train_inputs_ready = normalizeMinMax(train_inputs, normParams)\n",
    "        test_inputs_ready = normalizeMinMax(test_inputs, normParams)\n",
    "    else\n",
    "        train_inputs_ready = train_inputs\n",
    "        test_inputs_ready = test_inputs\n",
    "    end\n",
    "\n",
    "    raw_cv_scores = Dict{String, Vector{Float64}}()\n",
    "    # --- INTERNAL HELPER: CALCOLO METRICHE ---\n",
    "    function calculate_metrics_safe(y_pred_probs, y_pred_class, y_true_class, y_true_onehot, classes)\n",
    "        auc_score = 0.5\n",
    "        acc, sens, spec, f1 = 0.0, 0.0, 0.0, 0.0\n",
    "        \n",
    "        if length(classes) == 2\n",
    "             # --- CALCOLO AUC REALE ---\n",
    "             try\n",
    "                probs = vec(y_pred_probs)\n",
    "                # Se abbiamo probabilitÃ  valide (non tutte zero)\n",
    "                if sum(probs) > 0\n",
    "                    true_bin = vec(y_true_onehot)\n",
    "                    \n",
    "                    p = sortperm(probs)\n",
    "                    probs_sorted = probs[p]\n",
    "                    true_sorted = true_bin[p]\n",
    "\n",
    "                    tpr = [0.0]; fpr = [0.0]\n",
    "                    num_pos = sum(true_sorted)\n",
    "                    num_neg = length(true_sorted) - num_pos\n",
    "\n",
    "                    if num_pos > 0 && num_neg > 0\n",
    "                        tp = 0; fp = 0\n",
    "                        for i in length(probs_sorted):-1:1\n",
    "                            if true_sorted[i] == 1; tp += 1; else; fp += 1; end\n",
    "                            push!(tpr, tp/num_pos)\n",
    "                            push!(fpr, fp/num_neg)\n",
    "                        end\n",
    "                        # Regola del trapezio\n",
    "                        auc_score = 0.0\n",
    "                        for i in 2:length(tpr)\n",
    "                            auc_score += (fpr[i] - fpr[i-1]) * (tpr[i] + tpr[i-1]) / 2\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "             catch e\n",
    "                 # println(\"Debug: AUC calculation failed: $e\")\n",
    "             end\n",
    "             # --------------------------\n",
    "\n",
    "             pos_label = classes[end]\n",
    "             y_p_bool = vec(y_pred_class .== pos_label)\n",
    "             y_t_bool = vec(y_true_class .== pos_label)\n",
    "             (acc, err, sens, spec, prec, npv, f1, cm) = confusionMatrix(y_p_bool, y_t_bool)\n",
    "        else\n",
    "             cm_res = confusionMatrix(y_pred_class, y_true_class, classes; weighted=true)\n",
    "             acc, sens, spec, f1 = cm_res.accuracy, cm_res.aggregated.sensitivity, cm_res.aggregated.specificity, cm_res.aggregated.f1\n",
    "        end\n",
    "        return Dict(\"Accuracy\"=>acc, \"AUC\"=>auc_score, \"Sensitivity\"=>sens, \"Specificity\"=>spec, \"F1\"=>f1)\n",
    "    end\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 1. Artificial Neural Networks (ANNs)\n",
    "    # ========================================================================\n",
    "    println(\"\\n[1/5] Testing ANNs...\")\n",
    "    ann_topologies = [[256], [128], [64], [32], [256, 128], [128, 64], [64, 32], [96, 48]]\n",
    "    best_f1_cv_ann = -1.0; best_topo_ann = []; best_raw_ann = []\n",
    "    \n",
    "    for topology in ann_topologies\n",
    "        hyperparams = Dict(\"topology\" => topology, \"learningRate\" => 0.003, \"validationRatio\" => 0.1, \n",
    "                           \"numExecutions\" => 1, \"maxEpochs\" => 800, \"maxEpochsVal\" => 25)\n",
    "        # ANN usa la sua CV interna che non ha il flag normalize, quindi passiamo i dati pronti\n",
    "        res = modelCrossValidation(:ANN, hyperparams, (train_inputs_ready, train_targets), cv_indices)\n",
    "        if res[7][1] > best_f1_cv_ann\n",
    "            best_f1_cv_ann = res[7][1]; best_topo_ann = topology; best_raw_ann = res[9] \n",
    "        end\n",
    "    end\n",
    "    raw_cv_scores[\"ANN\"] = best_raw_ann\n",
    "    println(\"   âœ¨ Best ANN (CV): $best_topo_ann - CV F1: $(round(best_f1_cv_ann*100, digits=2))%\")\n",
    "\n",
    "    println(\"      ...Retraining Best ANN & Plotting Loss...\")\n",
    "    N_train = size(train_inputs_norm, 1); (train_idx, val_idx) = holdOut(N_train, 0.1)\n",
    "    \n",
    "    final_ann, train_l, val_l, _ = _trainClassANN(best_topo_ann,\n",
    "        (train_inputs_norm[train_idx, :], train_targets_onehot[train_idx, :]),\n",
    "        validationDataset=(train_inputs_norm[val_idx, :], train_targets_onehot[val_idx, :]),\n",
    "        testDataset=(test_inputs_norm, test_targets_onehot),\n",
    "        maxEpochs=800, learningRate=0.003, maxEpochsVal=25)\n",
    "    plot_loss_curves(train_l, val_l, title=\"ANN Loss ($approach_name)\")\n",
    "\n",
    "    test_outputs_ann_raw = final_ann(test_inputs_norm')'\n",
    "    if size(test_targets_onehot, 2) == 1\n",
    "        probs_ann = vec(test_outputs_ann_raw); preds_ann_int = Int.(probs_ann .>= 0.5)\n",
    "    else\n",
    "        preds_bool = classifyOutputs(test_outputs_ann_raw)\n",
    "        preds_ann_int = [findfirst(x->x, row) - 1 for row in eachrow(preds_bool)]\n",
    "        probs_ann = test_outputs_ann_raw # Multiclass AUC placeholder\n",
    "    end\n",
    "    final_results[\"ANN\"] = calculate_metrics_safe(probs_ann, preds_ann_int, test_targets, test_targets_onehot, classes_int)\n",
    "    println(\"      âœ… ANN Test Results: F1=$(round(final_results[\"ANN\"][\"F1\"], digits=3))\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # 2. Support Vector Machines (SVMs)\n",
    "    # ========================================================================\n",
    "    println(\"\\n[2/5] Testing SVMs...\")\n",
    "    svm_configs = [\n",
    "        (\"linear\", 0.1, 0.125, 3), (\"linear\", 1.0, 0.125, 3), (\"linear\", 10.0, 0.125, 3),\n",
    "        (\"rbf\", 0.1, 0.125, 3), (\"rbf\", 1.0, 0.125, 3), (\"rbf\", 10.0, 0.125, 3), (\"rbf\", 1.0, 0.1, 3),\n",
    "        (\"poly\", 1.0, 0.125, 2), (\"poly\", 1.0, 0.125, 3), (\"poly\", 10.0, 0.125, 2)\n",
    "    ]\n",
    "    best_f1_cv_svm = -1.0; best_params_svm = (); best_raw_svm = []\n",
    "    \n",
    "    for (kernel, C, gamma, degree) in svm_configs\n",
    "        # MLJ models: passiamo i dati GREZZI e lasciamo fare al CV in base al flag\n",
    "        res = modelCrossValidation(:SVC, Dict(\"kernel\"=>kernel, \"C\"=>C, \"gamma\"=>gamma, \"degree\"=>degree), \n",
    "                                   (train_inputs, train_targets), cv_indices; normalize=do_normalize)\n",
    "        if res[7][1] > best_f1_cv_svm\n",
    "            best_f1_cv_svm = res[7][1]; best_params_svm = (kernel, C, gamma, degree); best_raw_svm = res[9] \n",
    "        end\n",
    "    end\n",
    "    raw_cv_scores[\"SVM\"] = best_raw_svm\n",
    "    k_name, C_val, g_val, d_val = best_params_svm\n",
    "    println(\"   âœ¨ Best SVM (CV): $k_name C=$C_val - CV F1: $(round(best_f1_cv_svm*100, digits=2))%\")\n",
    "    \n",
    "    k_func = k_name == \"linear\" ? LIBSVM.Kernel.Linear : (k_name == \"poly\" ? LIBSVM.Kernel.Polynomial : LIBSVM.Kernel.RadialBasis)\n",
    "    model_svm = SVMClassifier(kernel=k_func, cost=C_val, gamma=g_val, degree=Int32(d_val), probability=true) # <--- Probability=true\n",
    "    mach_svm = machine(model_svm, MLJ.table(train_inputs_ready), categorical(train_targets_str))\n",
    "    MLJ.fit!(mach_svm, verbosity=0)\n",
    "    preds_svm_str = string.(MLJ.predict(mach_svm, MLJ.table(test_inputs_norm)))\n",
    "    # SVM probabilities are tricky/slow in LIBSVM, keeping zeros\n",
    "    final_results[\"SVM\"] = calculate_metrics_safe(zeros(length(preds_svm_str)), preds_svm_str, test_targets_str, test_targets_onehot, classes_str)\n",
    "    println(\"      âœ… SVM Test Results: F1=$(round(final_results[\"SVM\"][\"F1\"], digits=3))\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # 3. Decision Trees\n",
    "    # ========================================================================\n",
    "    println(\"\\n[3/5] Testing DT...\")\n",
    "    depths = [3, 5, 7, 10, 15, 20, -1]\n",
    "    best_f1_cv_dt = -1.0; best_depth = 0; best_raw_dt = []\n",
    "    for d in depths\n",
    "        res = modelCrossValidation(:DecisionTreeClassifier, Dict(\"max_depth\"=>d), \n",
    "                                   (train_inputs, train_targets), cv_indices; normalize=do_normalize)\n",
    "        if res[7][1] > best_f1_cv_dt\n",
    "            best_f1_cv_dt = res[7][1]; best_depth = d; best_raw_dt = res[9] \n",
    "        end\n",
    "    end\n",
    "    raw_cv_scores[\"DT\"] = best_raw_dt\n",
    "    println(\"   âœ¨ Best DT (CV): Depth=$best_depth - CV F1: $(round(best_f1_cv_dt*100, digits=2))%\")\n",
    "    \n",
    "    model_dt = DTClassifier(max_depth=best_depth, rng=Random.MersenneTwister(42))\n",
    "    mach_dt = machine(model_dt, MLJ.table(train_inputs_ready), categorical(train_targets_str))\n",
    "    MLJ.fit!(mach_dt, verbosity=0)\n",
    "    preds_dt_raw = MLJ.predict(mach_dt, MLJ.table(test_inputs_norm))\n",
    "    preds_dt_str = string.(mode.(preds_dt_raw))\n",
    "    \n",
    "    # Try extract probs for DT\n",
    "    probs_dt = zeros(length(preds_dt_str))\n",
    "    try\n",
    "        # Attempt to get probability of the positive class (usually second class)\n",
    "        target_class = classes_str[end] \n",
    "        probs_dt = pdf.(preds_dt_raw, target_class)\n",
    "    catch; end\n",
    "\n",
    "    final_results[\"DT\"] = calculate_metrics_safe(probs_dt, preds_dt_str, test_targets_str, test_targets_onehot, classes_str)\n",
    "    println(\"      âœ… DT Test Results: F1=$(round(final_results[\"DT\"][\"F1\"], digits=3))\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # 4. kNN\n",
    "    # ========================================================================\n",
    "    println(\"\\n[4/5] Testing kNN...\")\n",
    "    k_vals = [1, 3, 5, 7, 10, 15]\n",
    "    best_f1_cv_knn = -1.0; best_k = 0; best_raw_knn = []\n",
    "    for k in k_vals\n",
    "        res = modelCrossValidation(:KNeighborsClassifier, Dict(\"n_neighbors\"=>k), \n",
    "                                   (train_inputs, train_targets), cv_indices; normalize=do_normalize)\n",
    "        if res[7][1] > best_f1_cv_knn\n",
    "            best_f1_cv_knn = res[7][1]; best_k = k; best_raw_knn = res[9] \n",
    "        end\n",
    "    end\n",
    "    raw_cv_scores[\"kNN\"] = best_raw_knn\n",
    "    println(\"   âœ¨ Best kNN (CV): k=$best_k - CV F1: $(round(best_f1_cv_knn*100, digits=2))%\")\n",
    "    \n",
    "    model_knn = kNNClassifier(K=best_k)\n",
    "    mach_knn = machine(model_knn, MLJ.table(train_inputs_ready), categorical(train_targets_str))\n",
    "    MLJ.fit!(mach_knn, verbosity=0)\n",
    "    preds_knn_raw = MLJ.predict(mach_knn, MLJ.table(test_inputs_norm))\n",
    "    preds_knn_str = string.(mode.(preds_knn_raw))\n",
    "    \n",
    "    # Try extract probs for kNN\n",
    "    probs_knn = zeros(length(preds_knn_str))\n",
    "    try\n",
    "        target_class = classes_str[end]\n",
    "        probs_knn = pdf.(preds_knn_raw, target_class)\n",
    "    catch; end\n",
    "\n",
    "    final_results[\"kNN\"] = calculate_metrics_safe(probs_knn, preds_knn_str, test_targets_str, test_targets_onehot, classes_str)\n",
    "    println(\"      âœ… kNN Test Results: F1=$(round(final_results[\"kNN\"][\"F1\"], digits=3))\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # 5. ENSEMBLES & FINAL PLOTS\n",
    "    # ========================================================================\n",
    "    println(\"\\n[5/5] Ensemble & Plots...\")\n",
    "    \n",
    "    w_ann, w_dt, w_knn = best_f1_cv_ann, best_f1_cv_dt, best_f1_cv_knn\n",
    "    weights = [w_ann, w_dt, w_knn] ./ sum([w_ann, w_dt, w_knn])\n",
    "    println(\"      âš–ï¸  Weights (CV-based): ANN=$(round(weights[1],digits=2)), DT=$(round(weights[2],digits=2)), kNN=$(round(weights[3],digits=2))\")\n",
    "\n",
    "    preds_ann_str = string.(preds_ann_int)\n",
    "    all_preds = [preds_ann_str, preds_dt_str, preds_knn_str]\n",
    "    \n",
    "    maj_preds = majorityVoting(all_preds)\n",
    "    final_results[\"MajorityVoting\"] = calculate_metrics_safe(zeros(length(maj_preds)), maj_preds, test_targets_str, test_targets_onehot, classes_str)\n",
    "    println(\"      âœ… Majority Voting: F1=$(round(final_results[\"MajorityVoting\"][\"F1\"], digits=3))\")\n",
    "\n",
    "    weighted_preds = weightedVoting(all_preds, weights)\n",
    "    final_results[\"WeightedVoting\"] = calculate_metrics_safe(zeros(length(weighted_preds)), weighted_preds, test_targets_str, test_targets_onehot, classes_str)\n",
    "    println(\"      âœ… Weighted Voting: F1=$(round(final_results[\"WeightedVoting\"][\"F1\"], digits=3))\")\n",
    "\n",
    "    println(\"\\nðŸ“Š Plotting Final Confusion Matrix (Weighted Voting)...\")\n",
    "    cm_matrix_to_plot = nothing\n",
    "    if length(classes_str) == 2\n",
    "        pos_label = classes_str[2]\n",
    "        y_p_bool = weighted_preds .== pos_label\n",
    "        y_t_bool = test_targets_str .== pos_label\n",
    "        (_, _, _, _, _, _, _, cm_matrix_to_plot) = confusionMatrix(y_p_bool, y_t_bool)\n",
    "    else\n",
    "        cm_res = confusionMatrix(weighted_preds, test_targets_str, classes_str; weighted=true)\n",
    "        cm_matrix_to_plot = cm_res.CM\n",
    "    end\n",
    "    plot_confusion_matrix(cm_matrix_to_plot, classes_str, title=\"Weighted Voting CM ($approach_name)\")\n",
    "\n",
    "    println(\"ðŸ“Š Plotting CV Comparison Boxplot...\")\n",
    "    models_to_plot = [\"ANN\", \"SVM\", \"DT\", \"kNN\"]\n",
    "    scores_to_plot = []\n",
    "    valid_models_boxplot = []\n",
    "    for m in models_to_plot\n",
    "        if haskey(raw_cv_scores, m) && !isempty(raw_cv_scores[m])\n",
    "            push!(scores_to_plot, raw_cv_scores[m])\n",
    "            push!(valid_models_boxplot, m)\n",
    "        end\n",
    "    end\n",
    "    if !isempty(scores_to_plot)\n",
    "        plot_model_comparison_boxplot(valid_models_boxplot, scores_to_plot)\n",
    "    else\n",
    "        println(\"âš ï¸ No CV data available for boxplot.\")\n",
    "    end\n",
    "\n",
    "    println(\"\\nðŸ§ª STATISTICAL SIGNIFICANCE TESTS (CV Scores)\")\n",
    "    if length(valid_models_boxplot) >= 2\n",
    "        means = mean.(scores_to_plot)\n",
    "        sorted_idx = sortperm(means, rev=true)\n",
    "        best_idx, second_idx = sorted_idx[1], sorted_idx[2]\n",
    "        \n",
    "        println(\"   Comparing Top 2 Models: $(valid_models_boxplot[best_idx]) vs $(valid_models_boxplot[second_idx])\")\n",
    "        println(\"   Mean F1: $(round(means[best_idx],digits=4)) vs $(round(means[second_idx],digits=4))\")\n",
    "        try\n",
    "            ttest = OneSampleTTest(scores_to_plot[best_idx] .- scores_to_plot[second_idx])\n",
    "            pval = pvalue(ttest)\n",
    "            println(\"   t-test p-value: $(round(pval, digits=5))\")\n",
    "            if pval < 0.05\n",
    "                println(\"   âœ… Significant Difference (p < 0.05) -> Winner is strictly better.\")\n",
    "            else\n",
    "                println(\"   âŒ No Significant Difference (p >= 0.05) -> Performance is comparable.\")\n",
    "            end\n",
    "        catch e\n",
    "            println(\"   âš ï¸ Could not perform t-test: $e\")\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return final_results\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59226d32-d227-4e1f-961f-607df6634244",
   "metadata": {},
   "source": [
    "## 1. Data Loading & 3-Class Target Creation\n",
    "\n",
    "**Dataset:** Fraudulent E-Commerce Transaction Data (1.5M transactions)\n",
    "\n",
    "**Target Creation Strategy:**\n",
    "- Original: Binary fraud labels (fraud vs non-fraud)\n",
    "- **Our approach:** 3-class risk assessment based on multiple signals:\n",
    "  1. **Time Risk:** Night transactions (0-5am, 11pm)\n",
    "  2. **Amount Risk:** High-value transactions (>90th percentile)\n",
    "  3. **Account Age Risk:** New accounts (<30 days)\n",
    "\n",
    "**Class Mapping:**\n",
    "- **Class 0 (LEGITTIMO):** Low-risk, legitimate transactions\n",
    "- **Class 1 (SOSPETTO):** Borderline cases requiring manual review\n",
    "- **Class 2 (FRAUDOLENTO):** High-risk fraudulent transactions\n",
    "\n",
    "**Justification:** This approach allows for graduated risk assessment, enabling businesses to:\n",
    "- Automatically approve low-risk transactions (Class 0)\n",
    "- Flag suspicious cases for manual review (Class 1)\n",
    "- Immediately block high-risk frauds (Class 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de582c0d-ce18-4b53-ae3b-8bbc64b19877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "#              DATA LOADING & 3-CLASS TARGET CREATION\n",
    "# ============================================================================\n",
    "\n",
    "const DATA_PATH = \"datasets/Fraudulent_E-Commerce_Transaction_Data_merge.csv\"\n",
    "println(\"\\n\" * \"=\"^70)\n",
    "println(\"ðŸ“‚ LOADING DATA\")\n",
    "println(\"=\"^70)\n",
    "\n",
    "df = CSV.read(DATA_PATH, DataFrame)\n",
    "target_col = \"Is Fraudulent\"\n",
    "\n",
    "println(\"Original dataset size: $(size(df))\")\n",
    "println(\"Original fraud distribution:\")\n",
    "println(\"  Non-fraud: $(sum(df[!, target_col] .== 0))\")\n",
    "println(\"  Fraud:     $(sum(df[!, target_col] .== 1))\")\n",
    "\n",
    "# Create 3-class target\n",
    "println(\"\\n\" * \"=\"^70)\n",
    "println(\"ðŸŽ¯ CREATING 3-CLASS TARGET\")\n",
    "println(\"=\"^70)\n",
    "\n",
    "df_with_classes = create_risk_classes(df, target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9199d34c-9167-4dfd-92e2-d4fa2175fb37",
   "metadata": {},
   "source": [
    "## 2. Class Balancing & Train/Test Split\n",
    "\n",
    "**Challenge:** Highly imbalanced dataset (90% Legitimate, 8.6% Suspicious, 1.4% Fraudulent)\n",
    "\n",
    "**Solution:** Undersample majority classes to match minority class (20,654 samples per class)\n",
    "\n",
    "**Train/Test Split:**\n",
    "- **80% Training** (49,569 samples) - used for cross-validation and model selection\n",
    "- **20% Test** (12,393 samples) - held out for final evaluation\n",
    "\n",
    "**Critical:** Test set is NEVER used during training or model selection to prevent data leakage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75628c65-341c-40c6-8e51-ddcc02957a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "#          CLASS BALANCING & TRAIN/TEST SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "println(\"\\n\" * \"=\"^70)\n",
    "println(\"âœ… TRAIN/TEST SPLIT (80% Train / 20% Test)\")\n",
    "println(\"=\"^70)\n",
    "\n",
    "# Balance classes\n",
    "class_0 = df_with_classes[df_with_classes.Risk_Class .== 0, :]\n",
    "class_1 = df_with_classes[df_with_classes.Risk_Class .== 1, :]\n",
    "class_2 = df_with_classes[df_with_classes.Risk_Class .== 2, :]\n",
    "\n",
    "n_min = minimum([size(class_0, 1), size(class_1, 1), size(class_2, 1)])\n",
    "n_target = min(n_min, 1000)\n",
    "\n",
    "println(\"\\nðŸ”„ Balancing dataset...\")\n",
    "println(\"  Samples per class: $n_target\")\n",
    "\n",
    "class_0_sample = class_0[shuffle(1:size(class_0, 1))[1:n_target], :]\n",
    "class_1_sample = class_1[shuffle(1:size(class_1, 1))[1:n_target], :]\n",
    "class_2_sample = class_2[shuffle(1:size(class_2, 1))[1:n_target], :]\n",
    "\n",
    "df_balanced = vcat(class_0_sample, class_1_sample, class_2_sample)\n",
    "df_balanced = df_balanced[shuffle(1:size(df_balanced, 1)), :]\n",
    "\n",
    "println(\"  Balanced dataset size: $(size(df_balanced))\")\n",
    "\n",
    "# Split Train/Test BEFORE preprocessing (critical!)\n",
    "n_total = size(df_balanced, 1)\n",
    "n_train = floor(Int, n_total * 0.80)\n",
    "n_test = n_total - n_train\n",
    "\n",
    "all_indices = shuffle(1:n_total)\n",
    "train_indices = all_indices[1:n_train]\n",
    "test_indices = all_indices[n_train+1:end]\n",
    "\n",
    "df_train = df_balanced[train_indices, :]\n",
    "df_test = df_balanced[test_indices, :]\n",
    "\n",
    "println(\"\\nðŸ“Š Split Summary:\")\n",
    "println(\"  Total samples:     $n_total\")\n",
    "println(\"  Training set:      $n_train (80%)\")\n",
    "println(\"  Test set:          $n_test (20%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5c850a-1ee0-47f8-8ba8-5ffbb6db6706",
   "metadata": {},
   "source": [
    "## 3. Preprocessing & Feature Engineering\n",
    "\n",
    "**Steps:**\n",
    "1. **Time Features:** Extract hour, create night flag (hour < 6)\n",
    "2. **Feature Engineering:**\n",
    "   - `Amount_per_AccountAge`: Transaction amount relative to account maturity\n",
    "   - `High_Value_Flag`: Transactions above 95th percentile\n",
    "   - `New_Account_Flag`: Accounts younger than 30 days\n",
    "3. **Missing Value Imputation:** Median imputation\n",
    "4. **Feature Selection:** Drop IDs, addresses, categorical features â†’ **8 numerical features**\n",
    "5. **Normalization:** Min-Max [0,1] using training set parameters only\n",
    "\n",
    "**Final Features (8):**\n",
    "- Transaction Amount\n",
    "- Account Age Days  \n",
    "- Transaction_Hour\n",
    "- Is_Night\n",
    "- Amount_per_AccountAge\n",
    "- High_Value_Flag\n",
    "- New_Account_Flag\n",
    "- (1 more from preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491a8af7-0d2a-4e4a-a9f3-73416da93e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "#                    PREPROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "println(\"\\nðŸ”§ Preprocessing train and test sets...\")\n",
    "\n",
    "# 1. Fit & Transform sul Train Set\n",
    "# Otteniamo sia il dataframe processato CHE le statistiche calcolate (train_stats)\n",
    "df_train_processed, train_stats = preprocess_multiclass(df_train, target_col)\n",
    "\n",
    "# 2. Transform sul Test Set\n",
    "# Passiamo 'train_stats' per forzare l'uso delle statistiche del train (mediane, percentili)\n",
    "# in modo che il test set non \"contamini\" il processo.\n",
    "df_test_processed = preprocess_multiclass(df_test, target_col; stats=train_stats)\n",
    "\n",
    "println(\"  Stats used for preprocessing (Calculated on Train):\")\n",
    "println(\"  Median Amount: $(train_stats[\"Transaction Amount_median\"])\")\n",
    "println(\"  High Value Threshold (p95): $(train_stats[\"amount_p95\"])\")\n",
    "\n",
    "# --- FIX PUNTO 1: RIMOZIONE DATA LEAKAGE ---\n",
    "# Escludiamo non solo la target variable, ma anche le feature create artificialmente \n",
    "# che definiscono le regole IF/THEN (Is_Night, High_Value, New_Account).\n",
    "# Lasciamo solo i dati grezzi e le feature derivate non banali.\n",
    "leakage_cols = [\"Risk_Class\", \"Is_Night\", \"High_Value_Flag\", \"New_Account_Flag\"]\n",
    "input_cols = setdiff(names(df_train_processed), leakage_cols)\n",
    "\n",
    "train_inputs = Matrix{Float32}(df_train_processed[:, input_cols])\n",
    "train_targets = Int.(df_train_processed.Risk_Class)\n",
    "\n",
    "test_inputs = Matrix{Float32}(df_test_processed[:, input_cols])\n",
    "test_targets = Int.(df_test_processed.Risk_Class)\n",
    "\n",
    "println(\"\\nðŸ“Š Preprocessed Data (Leakage-Free):\")\n",
    "println(\"  Features: $(length(input_cols))\")\n",
    "println(\"  Feature names: $input_cols\")\n",
    "println(\"  Train samples: $(size(train_inputs, 1))\")\n",
    "println(\"  Test samples: $(size(test_inputs, 1))\")\n",
    "println(\"\\n  Feature names: $input_cols\")\n",
    "\n",
    "# Create cross-validation indices (3-fold stratified)\n",
    "k_folds = 3\n",
    "cv_indices = crossvalidation(train_targets, k_folds)\n",
    "println(\"\\nâœ… Cross-validation indices created ($k_folds folds, stratified)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035e7d2f-dda1-4c71-8050-1ac38fd37097",
   "metadata": {},
   "source": [
    "# EXPERIMENT 1: Artificial Neural Networks (ANNs)\n",
    "\n",
    "**Configuration:**\n",
    "- **Topologies tested:** 8 architectures (1-4 hidden layers)\n",
    "- **Activation:** ReLU (hidden layers), Softmax (output)\n",
    "- **Optimizer:** Adam (learning rate: 0.003)\n",
    "- **Loss:** Cross-entropy\n",
    "- **Regularization:** Early stopping (patience: 25 epochs)\n",
    "- **Validation:** 10% of training set\n",
    "- **Executions:** 1 per topology (for speed; can increase for stability)\n",
    "\n",
    "**Architectures:**\n",
    "1. `[256]` - Large\n",
    "2. `[128]` - Medium\n",
    "3. `[64]` - Small\n",
    "4. `[32]` - Tiny\n",
    "5. `[256, 128]` - Large 2-layer\n",
    "6. `[128, 64]` - Medium 2-layer\n",
    "7. `[64, 32]` - Small 2-layer\n",
    "8. `[96, 48]` - Alternative 2-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af43fc5-26f1-4a0f-bea7-a3f6f104b9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "#  APPROACH 1: UNDERSAMPLING (BASE)\n",
    "#  Execution via evaluate_approach to ensure consistency, plots & stats.\n",
    "# ============================================================================\n",
    "\n",
    "println(\"\\n\" * \"#\"^70)\n",
    "println(\"ðŸ”¬ APPROACH 1: UNDERSAMPLING (Baseline)\")\n",
    "println(\"#\"^70)\n",
    "\n",
    "# Nota: train_inputs e train_targets sono giÃ  quelli undersampled (dal setup iniziale)\n",
    "results_app1 = evaluate_approach(\"1. Undersampling\", \n",
    "                                 train_inputs, train_targets, \n",
    "                                 test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08e8a98-7229-4f86-a84e-90297db63ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "#  APPROACH 2: OVERSAMPLING STRATEGY\n",
    "#  Description: Balance classes by duplicating minority samples instead of removing majority\n",
    "# ============================================================================\n",
    "\n",
    "println(\"\\n\" * \"#\"^70)\n",
    "println(\"ðŸ”¬ APPROACH 2: OVERSAMPLING\")\n",
    "println(\"#\"^70)\n",
    "\n",
    "# Function for Random Oversampling\n",
    "function random_oversampling(df, target_col)\n",
    "    classes = unique(df[!, target_col])\n",
    "    # Find count of majority class\n",
    "    max_count = maximum([sum(df[!, target_col] .== c) for c in classes])\n",
    "    \n",
    "    balanced_parts = []\n",
    "    for c in classes\n",
    "        df_class = df[df[!, target_col] .== c, :]\n",
    "        n_current = size(df_class, 1)\n",
    "        if n_current < max_count\n",
    "            # Oversample with replacement\n",
    "            ids = rand(1:n_current, max_count)\n",
    "            push!(balanced_parts, df_class[ids, :])\n",
    "        else\n",
    "            push!(balanced_parts, df_class)\n",
    "        end\n",
    "    end\n",
    "    return vcat(balanced_parts...)\n",
    "end\n",
    "\n",
    "# 1. Prepare Data (Oversampling on Training Data ONLY to prevent leakage)\n",
    "# Note: We use the raw training split created in Approach 1 section\n",
    "df_train_os = random_oversampling(df_train, \"Risk_Class\")\n",
    "\n",
    "# 2. Preprocess (Reuse existing function)\n",
    "df_train_os_proc, _ = preprocess_multiclass(df_train_os, \"Is Fraudulent\")\n",
    "# --- FIX LEAKAGE ANCHE QUI ---\n",
    "# Dobbiamo rimuovere le colonne \"spoiler\" anche dal dataset oversamplato\n",
    "leakage_cols = [\"Risk_Class\", \"Is_Night\", \"High_Value_Flag\", \"New_Account_Flag\"]\n",
    "input_cols_os = setdiff(names(df_train_os_proc), leakage_cols)\n",
    "# -----------------------------\n",
    "\n",
    "train_inputs_os = Matrix{Float32}(df_train_os_proc[:, input_cols_os])\n",
    "train_targets_os = Int.(df_train_os_proc.Risk_Class)\n",
    "\n",
    "# 3. Evaluate ALL models on this new dataset\n",
    "results_app3 = evaluate_approach(\"Oversampling\", train_inputs_os, train_targets_os, test_inputs, test_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86abe884-8b3b-4da4-a07d-4d734bcf1584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "#  APPROACH 3: FEATURE EXTRACTION (PCA)\n",
    "#  Description: Reduce dimensionality using PCA before modeling.\n",
    "#  CRITICAL FIX: PCA matrix (W) is calculated on TRAIN and applied to TEST.\n",
    "# ============================================================================\n",
    "\n",
    "using LinearAlgebra # Required for PCA\n",
    "\n",
    "println(\"\\n\" * \"#\"^70)\n",
    "println(\"ðŸ”¬ APPROACH 3: PCA FEATURE EXTRACTION\")\n",
    "println(\"#\"^70)\n",
    "\n",
    "\"\"\"\n",
    "    fit_pca(data, variance_threshold)\n",
    "    \n",
    "Calculates the projection matrix W and normalization parameters based on the provided data (Training Set).\n",
    "Returns: (W, norm_params)\n",
    "\"\"\"\n",
    "function fit_pca(data, variance_threshold=0.95)\n",
    "    # 1. Calculate normalization parameters on TRAIN data\n",
    "    # We use ZeroMean normalization (Standardization) which is standard for PCA\n",
    "    norm_params = calculateZeroMeanNormalizationParameters(data)\n",
    "    \n",
    "    # 2. Standardize the data\n",
    "    data_std = normalizeZeroMean(data, norm_params)\n",
    "    \n",
    "    # 3. Covariance Matrix & Eigen decomposition\n",
    "    C = cov(data_std)\n",
    "    F = eigen(C)\n",
    "    \n",
    "    # 4. Sort eigenvalues (descending) and corresponding vectors\n",
    "    idx = sortperm(F.values, rev=true)\n",
    "    evals = F.values[idx]\n",
    "    evecs = F.vectors[:, idx]\n",
    "    \n",
    "    # 5. Select components to reach variance threshold\n",
    "    cum_var = cumsum(evals ./ sum(evals))\n",
    "    k = findfirst(x -> x >= variance_threshold, cum_var)\n",
    "    \n",
    "    if isnothing(k)\n",
    "        k = size(data, 2) # Keep all if threshold not reached\n",
    "    end\n",
    "    \n",
    "    println(\"   PCA Fit: Retaining $k components (Variance covered: $(round(cum_var[k]*100, digits=2))%)\")\n",
    "    \n",
    "    # 6. Construct Projection Matrix W\n",
    "    W = evecs[:, 1:k]\n",
    "    \n",
    "    return W, norm_params\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    transform_data_pca(data, W, norm_params)\n",
    "    \n",
    "Projects new data into the PCA space defined by W, using existing normalization parameters.\n",
    "\"\"\"\n",
    "function transform_data_pca(data, W, norm_params)\n",
    "    # 1. Normalize using the PARAMETERS from the Training Set (Critical!)\n",
    "    # Note: We assume normalizeZeroMean handles parameter application correctly\n",
    "    data_std = normalizeZeroMean(data, norm_params)\n",
    "    \n",
    "    # 2. Project into PCA space\n",
    "    return data_std * W\n",
    "end\n",
    "\n",
    "# --- EXECUTION STEPS ---\n",
    "\n",
    "# 1. Fit PCA model on Training Data ONLY\n",
    "# We calculate W (eigenvectors) and normalization stats from train_inputs\n",
    "println(\"   1. Fitting PCA on Training Set...\")\n",
    "pca_W, pca_norm_params = fit_pca(train_inputs, 0.95)\n",
    "\n",
    "# 2. Transform Training Data\n",
    "println(\"   2. Transforming Training Set...\")\n",
    "train_inputs_pca = transform_data_pca(train_inputs, pca_W, pca_norm_params)\n",
    "\n",
    "# 3. Transform Test Data\n",
    "# CRITICAL: We use the SAME W and norm_params calculated on Train\n",
    "println(\"   3. Transforming Test Set (using Train projection)...\")\n",
    "test_inputs_pca = transform_data_pca(test_inputs, pca_W, pca_norm_params)\n",
    "\n",
    "# 4. Evaluate Models on the new PCA-transformed space\n",
    "# We pass both the transformed train and transformed test sets\n",
    "results_app4 = evaluate_approach(\"PCA (95% Variance)\", \n",
    "                                 train_inputs_pca, train_targets, \n",
    "                                 test_inputs_pca, test_targets; \n",
    "                                 do_normalize=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55b07d6-cb67-4a8a-a474-c52f02e3e20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "#  APPROACH 4: BINARY CLASSIFICATION (ORIGINAL GROUND TRUTH)\n",
    "#  Description: Train directly on the original \"Is Fraudulent\" label.\n",
    "#  Why: Class 1 (Suspicious) contains both Frauds and Risky Legitimate ones.\n",
    "#       Merging 1 & 2 would confuse the model. We use the true binary label.\n",
    "# ============================================================================\n",
    "\n",
    "println(\"\\n\" * \"#\"^70)\n",
    "println(\"ðŸ”¬ APPROACH 4: BINARY CLASSIFICATION (Original Fraud vs Not)\")\n",
    "println(\"#\"^70)\n",
    "\n",
    "# 1. Extract the Original Binary Targets (0/1)\n",
    "# We go back to df_train/df_test because preprocessing dropped the target column\n",
    "println(\"   Extracting original 'Is Fraudulent' labels from balanced dataframe...\")\n",
    "\n",
    "# Ensure we align with the rows used in train_inputs (which come from df_train)\n",
    "train_targets_binary = Int.(df_train[!, \"Is Fraudulent\"])\n",
    "test_targets_binary  = Int.(df_test[!, \"Is Fraudulent\"])\n",
    "\n",
    "# Check distribution\n",
    "n_fraud = sum(train_targets_binary .== 1)\n",
    "n_legit = sum(train_targets_binary .== 0)\n",
    "println(\"   Binary Train Distribution: Legit=$n_legit, Fraud=$n_fraud\")\n",
    "\n",
    "# 2. Evaluate ALL models on Binary Targets\n",
    "# The inputs (train_inputs) remain the same (we keep the feature engineering like \"Is_Night\", etc.)\n",
    "# but we aim for the true binary target.\n",
    "results_app5 = evaluate_approach(\"Binary\", train_inputs, train_targets_binary, test_inputs, test_targets_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b598055-3d55-49a8-99bb-d0c01b1f10b2",
   "metadata": {},
   "source": [
    "# Final Results & Comparison\n",
    "\n",
    "Comprehensive comparison of all 6 approaches on the hold-out test set.\n",
    "\n",
    "**Evaluation Metrics:**\n",
    "- **F1 Score:** Harmonic mean of precision and recall\n",
    "- **Accuracy:** Overall correct predictions\n",
    "- **Per-Class Metrics:** Performance for each risk level\n",
    "\n",
    "**Key Question:** Which approach best balances overall performance with fraud detection capability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1900c344-0ae9-401b-bbed-4074445fb81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "#  FINAL COMPARISON SUMMARY - FULL METRICS\n",
    "# ============================================================================\n",
    "\n",
    "println(\"\\n\" * \"=\"^100)\n",
    "println(\"ðŸ† FINAL DETAILED RESULTS & COMPARISON\")\n",
    "println(\"=\"^100)\n",
    "\n",
    "using Printf\n",
    "\n",
    "# --- 1. FUNZIONE DI STAMPA TABELLA ---\n",
    "function print_detailed_table(approach_name, res_dict)\n",
    "    println(\"\\nðŸ“Œ Approach: $approach_name\")\n",
    "    println(\"-\"^95)\n",
    "    @printf(\"%-18s | %-10s | %-10s | %-10s | %-10s | %-10s\\n\", \n",
    "            \"Model\", \"Accuracy\", \"Sensitiv.\", \"Specific.\", \"AUC-ROC\", \"F1-Score\")\n",
    "    println(\"-\"^95)\n",
    "    \n",
    "    # Ordine di stampa preferito\n",
    "    model_order = [\"ANN\", \"SVM\", \"DT\", \"kNN\", \"MajorityVoting\", \"WeightedVoting\"]\n",
    "    \n",
    "    # Trova quali modelli sono presenti nel dizionario\n",
    "    present_models = filter(m -> haskey(res_dict, m), model_order)\n",
    "    \n",
    "    for model in present_models\n",
    "        m = res_dict[model]\n",
    "        # Gestione sicura dei valori (se mancano mette 0.0)\n",
    "        acc  = get(m, \"Accuracy\", 0.0) * 100\n",
    "        sens = get(m, \"Sensitivity\", 0.0) * 100\n",
    "        spec = get(m, \"Specificity\", 0.0) * 100\n",
    "        auc  = get(m, \"AUC\", 0.0)\n",
    "        f1   = get(m, \"F1\", 0.0) * 100\n",
    "        \n",
    "        @printf(\"%-18s | %8.2f%%  | %8.2f%%  | %8.2f%%  | %8.4f     | %8.2f%%\\n\", \n",
    "                model, acc, sens, spec, auc, f1)\n",
    "    end\n",
    "    println(\"-\"^95)\n",
    "end\n",
    "\n",
    "# --- 2. RECUPERO DATI APPROCCIO 1 ---\n",
    "# Ora che usiamo evaluate_approach anche per l'Approccio 1, \n",
    "# abbiamo giÃ  il dizionario pronto nella variabile results_app1.\n",
    "# (Assicurati di aver eseguito la cella precedente dove chiami evaluate_approach per l'Appr. 1)\n",
    "\n",
    "if isdefined(Main, :results_app1)\n",
    "    results_app1_full = results_app1\n",
    "else\n",
    "    println(\"âš ï¸ Warning: results_app1 not found. Did you run Approach 1 via evaluate_approach?\")\n",
    "    results_app1_full = Dict()\n",
    "end\n",
    "\n",
    "# --- 3. STAMPA DELLE TABELLE ---\n",
    "\n",
    "# Lista di tutti gli approcci potenziali\n",
    "all_approaches = [\n",
    "    (\"1. Undersampling\", results_app1_full),\n",
    "    (\"2. Oversampling\", isdefined(Main, :results_app3) ? results_app3 : Dict()),\n",
    "    (\"3. PCA Features\", isdefined(Main, :results_app4) ? results_app4 : Dict()),\n",
    "    (\"4. Binary Class.\", isdefined(Main, :results_app5) ? results_app5 : Dict())\n",
    "]\n",
    "\n",
    "for (name, data) in all_approaches\n",
    "    if !isempty(data)\n",
    "        print_detailed_table(name, data)\n",
    "    else\n",
    "        println(\"\\nðŸ“Œ Approach: $name (Not Executed)\")\n",
    "    end\n",
    "end\n",
    "\n",
    "# --- 4. CALCOLO VINCITORE ASSOLUTO ---\n",
    "best_f1 = -1.0\n",
    "best_model_name = \"None\"\n",
    "best_approach_name = \"None\"\n",
    "\n",
    "for (app_name, data) in all_approaches\n",
    "    for (model, metrics) in data\n",
    "        if get(metrics, \"F1\", 0.0) > best_f1\n",
    "            global best_f1 = metrics[\"F1\"]\n",
    "            global best_model_name = model\n",
    "            global best_approach_name = app_name\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"\\n\" * \"=\"^80)\n",
    "println(\"ðŸŽ¯ OVERALL BEST PERFORMANCE\")\n",
    "println(\"   Approach: $best_approach_name\")\n",
    "println(\"   Model:    $best_model_name\")\n",
    "println(\"   F1 Score: $(round(best_f1*100, digits=2))%\")\n",
    "println(\"=\"^80)\n",
    "\n",
    "println(\"\\nðŸ“‹ PROJECT SUMMARY:\")\n",
    "println(\"  âœ… Tested 4 distinct Data Approaches (Under, Over, PCA, Binary)\")\n",
    "println(\"  âœ… Evaluated 4 ML Algorithms + Ensembles for EACH approach\")\n",
    "println(\"  âœ… Data Leakage prevention implemented (Strict Train/Test separation)\")\n",
    "println(\"  âœ… Full metrics comparison (Accuracy, Sensitivity, Specificity, AUC, F1)\")\n",
    "println(\"=\"^80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21fca29-19c9-494b-845e-cdbbcdc6421b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
